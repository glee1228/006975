{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bag_of_words.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/glee1228/006975/blob/master/bag_of_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzM-VytVcaJD",
        "colab_type": "text"
      },
      "source": [
        "# Image Recognition Using Bags of Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU7AlNYqce9f",
        "colab_type": "text"
      },
      "source": [
        "Referenced Code : https://github.com/CyrusChiu/Image-recognition\n",
        "\n",
        "Porting by glee1228@naver.com"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC2PC3tHcNLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import random\n",
        "import sklearn\n",
        "from sklearn.cluster import KMeans\n",
        "import scipy.cluster.vq as vq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvWidhwG3nhN",
        "colab_type": "text"
      },
      "source": [
        "## Google Drive Link\n",
        "for Downloading pkl files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ScN5ZGV3mMf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "138f9fbc-14b7-4b46-d838-f27b5caab9a5"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if os.path.exists('/content/gdrive')==False:\n",
        "    drive.mount('/content/gdrive')\n",
        "    print('Google Drive is mounted\\n')\n",
        "else:\n",
        "    print('Google Drive is already mounted\\n')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Google Drive is mounted\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qavf8WwP5_Uo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aa6cb075-3289-448b-d397-1f3e46047799"
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive')\n",
        "print('current path ? ',os.getcwd())\n",
        "print('List of files in the current path :',os.listdir(os.getcwd()))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current path ?  /content/gdrive/My Drive\n",
            "List of files in the current path : []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzyWTWBYcQUC",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Cifar-10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cENx-S7s0fWe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eae10518-bfdc-4725-b046-964de4136c26"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksjkxURExDJI",
        "colab_type": "text"
      },
      "source": [
        "## Opencv Downgrade\n",
        "3.4.3 version can not be used because of patents on SIFT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49HAzRqNwwF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "df9cf4ae-24fb-4805-9f38-afe0f9174f22"
      },
      "source": [
        "! yes | pip3 uninstall opencv-python\n",
        "\n",
        "! yes | pip3 uninstall opencv-contrib-python\n",
        "\n",
        "! yes | pip3 install opencv-python==3.4.2.16\n",
        " \n",
        "! yes | pip3 install opencv-contrib-python==3.4.2.16"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling opencv-python-3.4.2.16:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/cv2/*\n",
            "    /usr/local/lib/python3.6/dist-packages/opencv_python-3.4.2.16.dist-info/*\n",
            "Proceed (y/n)?   Successfully uninstalled opencv-python-3.4.2.16\n",
            "Uninstalling opencv-contrib-python-3.4.2.16:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/opencv_contrib_python-3.4.2.16.dist-info/*\n",
            "Proceed (y/n)?   Successfully uninstalled opencv-contrib-python-3.4.2.16\n",
            "Collecting opencv-python==3.4.2.16\n",
            "  Using cached https://files.pythonhosted.org/packages/fa/7d/5042b668a8ed41d2a80b8c172f5efcd572e3c046c75ae029407e19b7fc68/opencv_python-3.4.2.16-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.2.16) (1.16.4)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python\n",
            "Successfully installed opencv-python-3.4.2.16\n",
            "Collecting opencv-contrib-python==3.4.2.16\n",
            "  Using cached https://files.pythonhosted.org/packages/08/f1/66330f4042c4fb3b2d77a159db8e8916d9cdecc29bc8c1f56bc7f8a9bec9/opencv_contrib_python-3.4.2.16-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==3.4.2.16) (1.16.4)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "Successfully installed opencv-contrib-python-3.4.2.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPMeXNyJ0uQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhY-7F9RlT73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0dc622d1-cab0-4c9a-9ceb-6655065b1d8c"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBFPR3htdxB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67e8edff-856d-4b07-8c9e-8711e6889862"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p59LwB-cjgbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_sift_descriptors(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\n",
        "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
        "    return descriptors\n",
        "\n",
        "def build_codebook(X, voc_size):\n",
        "    \"\"\"\n",
        "    Inupt a list of feature descriptors\n",
        "    voc_size is the \"K\" in K-means, k is also called vocabulary size\n",
        "    Return the codebook/dictionary\n",
        "    \"\"\"\n",
        "    features = np.vstack((descriptor for descriptor in X))\n",
        "    kmeans = KMeans(n_clusters=voc_size, n_jobs=-1)\n",
        "    kmeans.fit(features)\n",
        "    codebook = kmeans.cluster_centers_.squeeze()\n",
        "    return codebook\n",
        "\n",
        "\n",
        "def input_vector_encoder(feature, codebook):\n",
        "    \"\"\"\n",
        "    Input all the local feature of the image\n",
        "    Pooling (encoding) by codebook and return\n",
        "    \"\"\"\n",
        "    code, _ = vq.vq(feature, codebook)\n",
        "    word_hist, bin_edges = np.histogram(code, bins=range(codebook.shape[0] + 1), normed=True)\n",
        "    return word_hist\n",
        "\n",
        "def bootstrap_x_y_resample(x,y, n=None):\n",
        "    if n == None:\n",
        "        n = len(x)\n",
        "    if len(x)!=len(y):\n",
        "        print('the number of data is not match the number of label')\n",
        "    resample_i = np.floor(np.random.rand(n) * len(x)).astype(int)\n",
        "    X_resample = np.array(x)[resample_i]\n",
        "    Y_resample = np.array(y)[resample_i]\n",
        "    # print('original label mean:', sum(np.array(y).astype(int)) / len(y))\n",
        "    # print('resampled label mean:', sum(np.array(Y_resample).astype(int)) / len(Y_resample))\n",
        "    return X_resample,Y_resample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WovZX982y0_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOC_SIZE = 100\n",
        "\n",
        "random.seed(777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZrl5OMr7I-E",
        "colab_type": "text"
      },
      "source": [
        "## Bag of Features Process\n",
        "### 1. feature extraction\n",
        "SIFT descriptors ... etc\n",
        "### 2. clustering and build codebook\n",
        "k-means algorithm .... etc\n",
        "### 3. Image representation(making the histogram of features)\n",
        "Vector Quantization Technique\n",
        "### 4. classifier learning and recognition\n",
        "SVM , Naive Bayes, ...etc\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv4WK2FUwd-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_extraction = False\n",
        "clustering_and_build_codebook = True\n",
        "image_representation = True\n",
        "learning_and_recognition = True\n",
        "run_all_process = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK61NIWaynce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if run_all_process:\n",
        "    feature_extraction = True\n",
        "    clustering_and_build_codebook = True\n",
        "    image_representation = True\n",
        "    learning_and_recognition = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tHCoGO-zSzi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "20c004a5-66d9-4ad3-f5c9-9c450cf0f084"
      },
      "source": [
        "if feature_extraction:\n",
        "    # Training\n",
        "    print(\"SIFT feature extraction\")\n",
        "    x_train = [extract_sift_descriptors(img) for img in x_train]\n",
        "    x_test = [extract_sift_descriptors(img) for img in x_test]\n",
        "    # Remove None in SIFT extraction\n",
        "    x_train = [each for each in zip(x_train, y_train) if not each[0] is None]\n",
        "    x_train, y_train = zip(*x_train)\n",
        "    x_test = [each for each in zip(x_test, y_test) if not each[0] is None]\n",
        "    x_test, y_test = zip(*x_test)\n",
        "    print(\"Train/Test split: {:d}/{:d}\".format(len(y_train), len(y_test)))\n",
        "    with open('./x_train.pkl','wb') as f:\n",
        "        pickle.dump(x_train, f)\n",
        "    with open('./x_test.pkl','wb') as f:\n",
        "        pickle.dump(x_test, f)\n",
        "    with open('./y_train.pkl', 'wb') as f:\n",
        "        pickle.dump(y_train, f)\n",
        "    with open('./y_test.pkl', 'wb') as f:\n",
        "        pickle.dump(y_test, f)\n",
        "else:\n",
        "    with open('./x_train.pkl','rb') as fp:\n",
        "        x_train = pickle.load(fp)\n",
        "    with open('./x_test.pkl','rb') as fp:\n",
        "        x_test = pickle.load(fp)\n",
        "    with open('./y_train.pkl','rb') as fp:\n",
        "        y_train = pickle.load(fp)\n",
        "    with open('./y_test.pkl','rb') as fp:\n",
        "        y_test = pickle.load(fp)\n",
        "    print(\"SIFT features ard loaded\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SIFT feature extraction\n",
            "Train/Test split: 49904/9976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsHIZ_cRwsl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class_value, class_count = np.unique(y_train, return_counts=True)\n",
        "# print('label value :',class_value)\n",
        "# print('count per label :', class_count)\n",
        "# print('Bootstrap n={} resampling'.format(n))\n",
        "# x_train, y_train = bootstrap_x_y_resample(x_train, y_train, n=n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI7iE0kB8FaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebeae2f0-3692-4028-ec6a-bd6ced0f2ea7"
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "print('the number of CPU using k-means clustering :',multiprocessing.cpu_count())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the number of CPU using k-means clustering : 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaXmNIYrzXUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a287160f-4127-438a-9769-f657767b6b17"
      },
      "source": [
        "codebook =None\n",
        "if clustering_and_build_codebook:\n",
        "    print(\"Building the codebook, it will take some time\")\n",
        "    codebook = build_codebook(x_train, voc_size=VOC_SIZE)\n",
        "    with open('./bow_codebook.pkl', 'wb') as f:\n",
        "        pickle.dump(codebook, f)\n",
        "else :\n",
        "    print('Loading the last codebook.')\n",
        "    with open('./bow_codebook.pkl','rb') as fp:\n",
        "        codebook = pickle.load(fp)\n",
        "print('Codebook Shape is ', codebook.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building the codebook, it will take some time\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn-bCTaJzZXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if image_representation:\n",
        "    print('Approximate data as codeword vectors by Vector Quantization and Making the histogram of data ')\n",
        "    print(\"Bag of words encoding\")\n",
        "    x_train = [input_vector_encoder(x, codebook) for x in x_train]\n",
        "    x_train = np.asarray(x_train)\n",
        "    x_test = [input_vector_encoder(each, codebook) for each in x_test]\n",
        "    x_test = np.asarray(x_test)\n",
        "    with open('./x_train_hist.pkl','wb') as f:\n",
        "        pickle.dump(x_train, f)\n",
        "    with open('./x_test_hist.pkl','wb') as f:\n",
        "        pickle.dump(x_test, f)\n",
        "else :\n",
        "    print('Loading the last Image representation')\n",
        "    with open('./x_train_hist.pkl','rb') as fp:\n",
        "        x_train = pickle.load(fp)\n",
        "    with open('./x_test_hist.pkl','rb') as fp:\n",
        "        x_test = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irPFciBQzcNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if learning_and_recognition:\n",
        "    svm_classifier(x_train, y_train, x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQEWX1nb7wFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}